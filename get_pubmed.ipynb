{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import PubmedGraphDataset\n",
    "from dgl import AddSelfLoop\n",
    "from dgl import to_networkx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "# Load the dataset\n",
    "transform = AddSelfLoop()  # Add self-loops\n",
    "data = PubmedGraphDataset(transform=transform)\n",
    "g = data[0]  # Get the first graph object from the dataset\n",
    "\n",
    "# Convert to NetworkX graph to easily get adjacency matrix, \n",
    "# or use DGL's own functions for adjacency matrix\n",
    "#adj = g.adjacency_matrix()  # Get adjacency matrix in CSR format #scipy_fmt=\"csr\"\n",
    "\n",
    "# Extract features\n",
    "features = g.ndata['feat']  # Node features\n",
    "\n",
    "# Extract labels\n",
    "labels = g.ndata['label']  # Node labels\n",
    "\n",
    "# Training, validation, and test indices\n",
    "# Assuming these are provided in the dataset (common in citation network datasets)\n",
    "# Otherwise, you'll need to create these splits\n",
    "idx_train = torch.nonzero(g.ndata['train_mask'], as_tuple=False).squeeze()\n",
    "idx_val = torch.nonzero(g.ndata['val_mask'], as_tuple=False).squeeze()\n",
    "idx_test = torch.nonzero(g.ndata['test_mask'], as_tuple=False).squeeze()\n",
    "\n",
    "# Convert adjacency matrix to dense format if needed\n",
    "# adj_dense = adj.todense()\n",
    "\n",
    "# Convert everything to the desired format, e.g., numpy arrays or torch tensors\n",
    "# Note: This step depends on what format you need for your use case\n",
    "features_np = features.numpy()  # Convert features to numpy array if needed\n",
    "labels_np = labels.numpy()  # Convert labels to numpy array if needed\n",
    "\n",
    "# idx_train, idx_val, and idx_test are already torch tensors; convert if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, dst = g.edges()\n",
    "num_nodes = g.num_nodes()\n",
    "\n",
    "# Create a sparse adjacency matrix\n",
    "# Note: Adjust 'dtype' as needed, e.g., for weighted graphs\n",
    "adj_sparse = sp.coo_matrix((torch.ones(src.shape[0]), (src.numpy(), dst.numpy())),\n",
    "                           shape=(num_nodes, num_nodes),\n",
    "                           dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pubmed_dgl/adj_sparse.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_npz\n\u001b[0;32m----> 2\u001b[0m \u001b[43mload_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpubmed_dgl/adj_sparse.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLMI4_env_2/lib/python3.10/site-packages/scipy/sparse/_matrix_io.py:125\u001b[0m, in \u001b[0;36mload_npz\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_npz\u001b[39m(file):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Load a sparse matrix from a file using ``.npz`` format.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m           [4, 0, 0]], dtype=int64)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mPICKLE_KWARGS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m loaded:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m             matrix_format \u001b[38;5;241m=\u001b[39m loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/MLMI4_env_2/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pubmed_dgl/adj_sparse.npz'"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import load_npz\n",
    "load_npz('pubmed_dgl/adj_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14442)\t1.0\n",
      "  (0, 1378)\t1.0\n",
      "  (0, 1544)\t1.0\n",
      "  (0, 6092)\t1.0\n",
      "  (0, 7636)\t1.0\n",
      "  (1, 10199)\t1.0\n",
      "  (1, 8359)\t1.0\n",
      "  (1, 2943)\t1.0\n",
      "  (2, 11485)\t1.0\n",
      "  (2, 15572)\t1.0\n",
      "  (2, 10471)\t1.0\n",
      "  (3, 8249)\t1.0\n",
      "  (4, 14044)\t1.0\n",
      "  (5, 1312)\t1.0\n",
      "  (5, 12968)\t1.0\n",
      "  (6, 17284)\t1.0\n",
      "  (6, 8661)\t1.0\n",
      "  (6, 3150)\t1.0\n",
      "  (6, 18614)\t1.0\n",
      "  (6, 7296)\t1.0\n",
      "  (6, 2216)\t1.0\n",
      "  (6, 8981)\t1.0\n",
      "  (6, 13656)\t1.0\n",
      "  (6, 6572)\t1.0\n",
      "  (6, 3509)\t1.0\n",
      "  :\t:\n",
      "  (19692, 19692)\t1.0\n",
      "  (19693, 19693)\t1.0\n",
      "  (19694, 19694)\t1.0\n",
      "  (19695, 19695)\t1.0\n",
      "  (19696, 19696)\t1.0\n",
      "  (19697, 19697)\t1.0\n",
      "  (19698, 19698)\t1.0\n",
      "  (19699, 19699)\t1.0\n",
      "  (19700, 19700)\t1.0\n",
      "  (19701, 19701)\t1.0\n",
      "  (19702, 19702)\t1.0\n",
      "  (19703, 19703)\t1.0\n",
      "  (19704, 19704)\t1.0\n",
      "  (19705, 19705)\t1.0\n",
      "  (19706, 19706)\t1.0\n",
      "  (19707, 19707)\t1.0\n",
      "  (19708, 19708)\t1.0\n",
      "  (19709, 19709)\t1.0\n",
      "  (19710, 19710)\t1.0\n",
      "  (19711, 19711)\t1.0\n",
      "  (19712, 19712)\t1.0\n",
      "  (19713, 19713)\t1.0\n",
      "  (19714, 19714)\t1.0\n",
      "  (19715, 19715)\t1.0\n",
      "  (19716, 19716)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(adj_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19717, 500])\n",
      "torch.Size([19717])\n",
      "tensor([1, 1, 0,  ..., 2, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0554, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0114, 0.0047,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0531, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0145, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 2, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n"
     ]
    }
   ],
   "source": [
    "print(idx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(labels):\n",
    "    # The classes must be sorted before encoding to enable static class encoding.\n",
    "    # In other words, make sure the first class always maps to index 0.\n",
    "    classes = sorted(list(set(labels)))\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "\n",
    "def normalize_features(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = normalize_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0554, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0114, 0.0047,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0531, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0145, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "features.shape\n",
    "features = torch.FloatTensor(np.array(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 2, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.graph(([0, 1, 2], [1, 2, 3]))\n",
    "g.adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=19717, num_edges=108365,\n",
       "      ndata_schemes={'feat': Scheme(shape=(500,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset\n",
    "from dgl import AddSelfLoop\n",
    "\n",
    "transform = (\n",
    "        AddSelfLoop()\n",
    "    )  # by default, it will first remove self-loops to prevent duplication\n",
    "data = PubmedGraphDataset(transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/ariellerosinski/My Drive/Cambridge/MLMI4/Project/Code/pyGAT/data/cora/Pubmed-Diabetes.NODE.paper.tab\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_MLMI1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
